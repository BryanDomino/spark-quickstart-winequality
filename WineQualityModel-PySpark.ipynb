{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "\n",
    "When using a Domino on-demand Spark cluster, any data that will be used, created, or modified as part of the interaction must go into an external data store.\n",
    "\n",
    "In this notebook we will be moving our data file from the imported git repo into a Domino Dataset and working with it there. \n",
    "\n",
    "When you create a Spark cluster attached to a Domino workspace or job, any Domino dataset accessible from the workspace or job will also be accessible from all components of the cluster under the same dataset mount path. Data can be accessed using the following path prefix:\n",
    "`file:///`\n",
    "\n",
    "For example, to read a file you would use the following:\n",
    "`rdd = sc.textFile(\"file:///path/to/file\")`\n",
    "\n",
    "\n",
    "To read from other data sources, see our docs [here](https://docs.dominodatalab.com/en/latest/user_guide/a3b42e/work-with-data/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = '/domino/datasets/local/' + os.environ['DOMINO_PROJECT_NAME'] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up data location \n",
    "\n",
    "#change the following line if you are not using the spark-quickstart-winequality repo as a Domino imported repo \n",
    "file_path = '/repos/spark-quickstart-winequality/wine_quality.csv'\n",
    "\n",
    "!cp $file_path $dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_path = dataset_path + '/wine_quality.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"WineQualityApp\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup and Test Spark Context\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "red_wine = spark.read.format('csv').options(header='true', inferSchema='true',sep=';').load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profile Data\n",
    "red_wine.printSchema()\n",
    "print(\"Rows: %s\" % red_wine.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction into Vectors\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# select the columns to be used as the features (all except `quality`)\n",
    "featureColumns = [c for c in red_wine.columns if c != 'quality']\n",
    "\n",
    "# create and configure the assembler\n",
    "assembler = VectorAssembler(inputCols=featureColumns, \n",
    "                            outputCol=\"features\")\n",
    "\n",
    "# transform the original data\n",
    "dataDF = assembler.transform(red_wine)\n",
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# fit a `LinearRegression` model using features in colum `features` and label in column `quality`\n",
    "lr = LinearRegression(maxIter=30, regParam=0.3, elasticNetParam=0.3, featuresCol=\"features\", labelCol=\"quality\")\n",
    "lrModel = lr.fit(dataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in zip(featureColumns, lrModel.coefficients):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the quality, the predicted quality will be saved in `prediction` column\n",
    "predictionsDF = lrModel.transform(dataDF)\n",
    "display(predictionsDF.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# create a regression evaluator with RMSE metrics\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol='quality', predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictionsDF)\n",
    "print(\"Root Mean Squared Error (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the input data into traning and test dataframes with 70% to 30% weights\n",
    "(trainingDF, testDF) = red_wine.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# construct the `Pipeline` that with two stages: the `vector assembler` and `regresion model estimator`\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# train the pipleline on the traning data\n",
    "lrPipelineModel = pipeline.fit(trainingDF)\n",
    "\n",
    "# make predictions\n",
    "traningPredictionsDF = lrPipelineModel.transform(trainingDF)\n",
    "testPredictionsDF = lrPipelineModel.transform(testDF)\n",
    "\n",
    "# evaluate the model on test and traning data\n",
    "print(\"RMSE on training data = %g\" % evaluator.evaluate(traningPredictionsDF))\n",
    "print(\"RMSE on test data = %g\" % evaluator.evaluate(testPredictionsDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Random Forest\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# define the random forest estimator\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"quality\", numTrees=100, maxBins=128, maxDepth=20, \\\n",
    "                           minInstancesPerNode=5, seed=33)\n",
    "rfPipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# train the random forest model\n",
    "rfPipelineModel = rfPipeline.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Accuracy of Random Forest\n",
    "rfTrainingPredictions = rfPipelineModel.transform(trainingDF)\n",
    "rfTestPredictions = rfPipelineModel.transform(testDF)\n",
    "print(\"Random Forest RMSE on training data = %g\" % evaluator.evaluate(rfTrainingPredictions))\n",
    "print(\"Random Forest RMSE on test data = %g\" % evaluator.evaluate(rfTestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop Spark context\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
